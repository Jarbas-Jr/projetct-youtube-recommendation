{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os modelos feitos, agora quero uma combinação deles que eu possa usar pra ter um resultado melhor do que eu posso ter com um só.\n",
    "\n",
    "Aqui nao vamos usar nada extremamente avançado de stacking, que sao metodos de ensemble muito mais complexo ate pelo tamanho dos dados a chance de funcionar nao e tao grande.\n",
    "\n",
    "Como são dados relativamente simples, o maximo que vamos tentar aqui e uma média ponderada.\n",
    "\n",
    "\n",
    "####  Até a parte do ensemble, tudo igual ao que fizemos aqui anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import bs4 as bs4\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "pd.set_option(\"max.columns\", 131)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#https://strftime.org/\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labels_curso - to_label_2.csv\", index_col=0).dropna(subset=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = pd.DataFrame(index=df.index)\n",
    "df_limpo['title'] = df['watch-title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Limpeza da data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date = df['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n",
    "clean_date[0] = clean_date[0].map(lambda x: \"0\"+x[0] if len(x) == 1 else x)\n",
    "#clean_date[1] = clean_date[1].map(lambda x: x[0].upper()+x[1:])\n",
    "\n",
    "mapa_meses = {\"jan\": \"Jan\",\n",
    "              \"fev\": \"Feb\",\n",
    "              \"mar\": \"Mar\", \n",
    "              \"abr\": \"Apr\", \n",
    "              \"mai\": \"May\", \n",
    "              \"jun\": \"Jun\",\n",
    "              \"jul\": \"Jul\",\n",
    "              \"ago\": \"Aug\", \n",
    "              \"set\": \"Sep\", \n",
    "              \"out\": \"Oct\", \n",
    "              \"nov\": \"Nov\",\n",
    "              \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(mapa_meses)\n",
    "\n",
    "clean_date = clean_date.apply(lambda x: \" \".join(x), axis=1)\n",
    "clean_date.head()\n",
    "df_limpo['date'] = pd.to_datetime(clean_date, format=\"%d %b %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpeza de Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False).str.replace(\".\", \"\").fillna(0).astype(int)\n",
    "df_limpo['views'] = views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df_limpo.index)\n",
    "y = df['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['tempo_desde_pub'] = (pd.to_datetime(\"2019-12-03\") - df_limpo['date']) / np.timedelta64(1, 'D')\n",
    "features['views'] = df_limpo['views']\n",
    "features['views_por_dia'] = features['views'] / features['tempo_desde_pub']\n",
    "features = features.drop(['tempo_desde_pub'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>views_por_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>28028</td>\n",
       "      <td>61.464912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>1161</td>\n",
       "      <td>21.109091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>141646</td>\n",
       "      <td>809.405714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>325</td>\n",
       "      <td>21.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>61</td>\n",
       "      <td>7.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      views  views_por_dia\n",
       "0     28028      61.464912\n",
       "394    1161      21.109091\n",
       "393  141646     809.405714\n",
       "392     325      21.666667\n",
       "391      61       7.625000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((555, 2), (609, 2), (555,), (609,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_train = df_limpo['date'] < \"2019-04-01\"\n",
    "mask_val = (df_limpo['date'] >= \"2019-04-01\")\n",
    "\n",
    "Xtrain, Xval = features[mask_train], features[mask_val]\n",
    "ytrain, yval = y[mask_train], y[mask_val]\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "title_train = df_limpo[mask_train]['title']\n",
    "title_val = df_limpo[mask_val]['title']\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=2, ngram_range=(1,3))\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 1144)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bow_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "Xtrain_wtitle = hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = hstack([Xval, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((555, 1146), (609, 1146))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle.shape, Xval_wtitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=6, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_rf = RandomForestClassifier(n_estimators=1000, random_state=0, min_samples_leaf=1, class_weight=\"balanced\", n_jobs=6)\n",
    "mdl_rf.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf = mdl_rf.predict_proba(Xval_wtitle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2284201947891743, 0.6926785398360559)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p_rf), roc_auc_score(yval, p_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarbasjr/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:546: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "params = [0.08265121231498246, 7, 1, 0.7251351011494334, 0.07547006552546137, 839, 2, 3]\n",
    "lr = params[0]\n",
    "max_depth = params[1]\n",
    "min_child_samples = params[2]\n",
    "subsample = params[3]\n",
    "colsample_bytree = params[4]\n",
    "n_estimators = params[5]\n",
    "\n",
    "min_df = params[6]\n",
    "ngram_range = (1, params[7])\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)\n",
    "\n",
    "Xtrain_wtitle = hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = hstack([Xval, title_bow_val])\n",
    "\n",
    "mdl_lgbm = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                     min_child_samples=min_child_samples, subsample=subsample,\n",
    "                     colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                     class_weight=\"balanced\", n_jobs=6)\n",
    "mdl_lgbm.fit(Xtrain_wtitle, ytrain)\n",
    "\n",
    "p_lgbm = mdl_lgbm.predict_proba(Xval_wtitle)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.247808743128664, 0.6717874624049065)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p_lgbm), roc_auc_score(yval, p_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obs\n",
    "\n",
    "A parte do \"scaler\" foi comentada.\n",
    "\n",
    "Se a Reg Log entrar no ensemble, na solução final, é muito mais facil usar o método \"make_pipeline\". Pois a gente simplesmente passa os transformadores e modelos que a gente quer usar e ele vai aplicando sequencialmente. Então quando eu passo MaxAbsScaler() e LogisticRegressiion() pra função make_pipeline ele vai fazer a mesma coisa que estavamos fazendo com fit_transform quando o scaler tava fora da função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.5, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=6, penalty='l2',\n",
       "                                    random_state=0, solver='lbfgs', tol=0.0001,\n",
       "                                    verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wtitle2 = csr_matrix(Xtrain_wtitle.copy())\n",
    "Xval_wtitle2 = csr_matrix(Xval_wtitle.copy())\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler = MaxAbsScaler()\n",
    "\n",
    "#Xtrain_wtitle2[:, :2] = scaler.fit_transform(Xtrain_wtitle2[:, :2].todense())\n",
    "#Xval_wtitle2[:, :2] = scaler.transform(Xval_wtitle2[:, :2].todense())\n",
    "#Xtrain_wtitle2 = scaler.fit_transform(Xtrain_wtitle2)\n",
    "#Xval_wtitle2 = scaler.transform(Xval_wtitle2)\n",
    "\n",
    "lr_pipeline = make_pipeline(MaxAbsScaler(), LogisticRegression(C=0.5, penalty='l2',n_jobs=6, random_state=0))\n",
    "lr_pipeline.fit(Xtrain_wtitle2, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lr = lr_pipeline.predict_proba(Xval_wtitle2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2150545436183453, 0.6870319042283423)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(yval, p_lr), roc_auc_score(yval, p_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anotando aqui todos os resultados e anotamos. Nós temos os scores de cada modelo. E a primeira coisa que Mario gosta de tentar é a média simples de todos os modelos.\n",
    "\n",
    "##### Random Forest\n",
    "(0.22228951304206077, 0.6914990859232175) RF  \n",
    "\n",
    "##### LightGBM\n",
    "(0.23779186526938, 0.6883293035324645) LGBM  \n",
    "\n",
    "##### Logistic Regression\n",
    "(0.2124987281512838, 0.6808987438815827) LR  \n",
    "\n",
    "\n",
    "##### LGBM após mudança em ngram_range, colocando parametro igual do RF para facilitar o deploy\n",
    "(0.247808743128664, 0.6717874624049065) LGBM ngram 1,3 - valor após mudança no ngram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24346920623544438, 0.6936958188358789)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Média simples de todos os modelos. A gente nao bate a \"average_precision\" mas bate a \"auc\".\n",
    "# Então, não é a solução que considerariamos final, mas ja é uma solução que não ta ruim.\n",
    "\n",
    "p = (p_lr + p_rf + p_lgbm)/3\n",
    "average_precision_score(yval, p), roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coisa importante quando estamos fazendo ensemble é que os modelos sejam diferentes entre si.\n",
    "\n",
    "E uma maneira de descobrir se os modelos estão encontrando soluções diferentes entre si é medir a correlação entre as previsões.\n",
    "\n",
    "Pegamos as três previsões e calculamos a correlação de pearson simplesinha abaixo.\n",
    "\n",
    "Olha que interessante, apesar de LGBM e RF serem dois modelos de ensemble de árvores, o LGBM só tem 0.55 de correlação com RF. Mario ja teve solução em competição que modelos com correlação de 0.97 entre eles e ainda assim melhoravam a solução. Então se a gente tem correlações tão baixas pra modelos com perfomances muito parecida, é um sinal bom que usando esses modelos juntos a gente vai ter um ganho.\n",
    "\n",
    "após mudarmos o ngram_range do lgbm, a correlação entre lgbm e rf caiu mais ainda, o que é bem bom, nao perdemos perfomance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LR</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820536</td>\n",
       "      <td>0.460369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF</td>\n",
       "      <td>0.820536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.460369</td>\n",
       "      <td>0.486359</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR        RF      LGBM\n",
       "LR    1.000000  0.820536  0.460369\n",
       "RF    0.820536  1.000000  0.486359\n",
       "LGBM  0.460369  0.486359  1.000000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"LR\": p_lr, \"RF\": p_rf, \"LGBM\": p_lgbm}).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de calcular a correlação, vamos tentar uma combinação somente random forest e lgbm pq são diferentes o bastante e tem uma perfomance muito boa comparada a reg log.\n",
    "\n",
    "Eu poderia fazer uma busca exaustiva de coeficientes pros três, mas quero tentar só com esses dois até pra simplificar a parte do deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24316089022038515, 0.6923394468361149)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resultado que eu tenho não bate o lgbm sozinho na ap, mas bate qualquer modelo na 'auc'\n",
    "# vamos especular os pesos, aumentando o  do lgbm, ficando 0.4/0.6, tivemos melhora, entao provavlmente estamos na direção certa\n",
    "# apesar do auc ter diminuido um pouco quando comparao ao 0.5/0.5, ainda está melhor que as soluções individuais\n",
    "\n",
    "# 0.3/0.7, essa variação na terceira casa é muito pequena, provavelmente é só ruido, mas a ap subiu bem com esses coef\n",
    "# tentando 0.2/0.8, melhorando pouco, nao significativa.\n",
    "# em 0.1/0.9 ja cai o desempenho, noassa maxima ta na região de 0.2/0.8\n",
    "# apesar do 0.2/0.8 ter sido um pouco melhor, vamos ficar com 0.3/0.7, pq a melhora nao é tão maior que conveça ficar com 0.8 pro lgbm\n",
    "# e tendo uma contribuição um pouco maior da random forest vamos ter um ensemble mais estavel, estará melhor distribuido o ensemble\n",
    "\n",
    "\n",
    "p = 0.5*p_rf + 0.5*p_lgbm\n",
    "average_precision_score(yval, p), roc_auc_score(yval, p)/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O LightGbm está com o TF-IDF diferente da random forest, na random forest o ngram_range é (1,3), e no lightgbm(1,5), e a gente poderia fazer o deploy disso numa boa, mas pra simplificar isso vamos tentar reduzir o tf-idf do lgbm e colocar os mesmos paramtros da random forest e ver se eu perco perfomance. Se ficar meio parecido a perfomance, eu prefiro ter só um tf-idf pra manter em produção do que os dois vectorizer pra ter um ganho muito pequeno.\n",
    "\n",
    "Então vou lá na lista \"params\" do lgbm e troco o ultimo item de 5 para 3, que representa a ultima banda do parametro ngram_range do tf-idf.\n",
    "\n",
    "Como resultado do lgbm individual, a ap melhorou e o auc caiu, pode ser que simplesmente ele não usou esse ngram_range pq nao encontrou na busca, se tivesse deixado um pouco mais de tempo ele buscando, ele poderia encontrar essa solução mas no nosso caso não encontrou e isso é perfeitamente normal.\n",
    "\n",
    "Uma coisa que mario gosta de fazer, depois da tunagem do bayesiam optmization é tunar um pouqinho manualmente, pra tentar de fato extrai o maximo, nao será feito aqui. Mudar só um pouco para valores vizinhos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.23117553771909904, 0.6964675355310491) - 0.5/0.5  \n",
    "(0.23866391160240463, 0.6962906174441233) - 0.4/0.6  \n",
    "(0.2449271153955049, 0.6967329126614378) - 0.3/0.7  \n",
    "(0.24568903874837777, 0.6967329126614378) - 0.2/0.8  \n",
    "\n",
    "\n",
    "##### Após mudança em ngram_range, colocando parametro igual do RF para facilitar o deploy\n",
    "\n",
    "(0.24567146005469367, 0.6897151618800496) - 0.3/0.7 - lgbm ngram 1,3\n",
    "\n",
    "(0.24809974466463763, 0.690865129445067) - 0.4/0.6 -  lgbm ngram 1,3\n",
    "\n",
    "\n",
    "Com 0.5/0.5 a ap cai bastante e auc melhora bem, nesse caso valeria a pena fazer o deploy da reg log, pq a media simples entre esses 3 modelos está batendo uma media ponderada só entre esses dois. Apesar de não bater o lgbm com o ngram em 3 sozinho na ap.\n",
    "\n",
    "Então agora é uma decisão subjetiva, eu posso fazer um deploy de uma solução bem mais complexa pq tem dois vectorizer e etc ou entao aceitar uma solução um pouco mais simples, média simples de dois modelos e ficar satisfeito, como estamos falando de um modelo simples, de uma primeira versão nao vamos perder tempo com isso e vamos colocar RF e LGBM em produção e o bom e que a gente já sabe que em algum momento a gente pode ir la e treinar mais esses modelos, Reg log e mudar o vectorizer de algum, mas num primeiro momento pra facilitar vamos usar só o RF e LGBM com apenas um vectorizer para o titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduzir complexidade do vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Salvar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chegou a hora de salvar os modelos.\n",
    "\n",
    "Mario gosta de usar joblib, pq e o recomendado pelo numpy e ele prefere do que o pickle, pq ele parece ser mais estavel para lidar com o tipo de array por trás desses modelos.\n",
    "\n",
    "Salvando todos apesar de só usar lgbm e rf. tanto que comentamos reg log.\n",
    "\n",
    "Isso vai salvar exatamente os modelos treinados pra gente em um objeto que a gente simplesmente vai usar a função jb.load() e vai carregar o nome desses arquivos e aplicar primeiro o title_vec e depois o light_gbm e a random forest nos nossos novos exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title_vectorizer_20200208.pkl.z']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.dump(mdl_lgbm, \"lgbm_20200208.pkl.z\")\n",
    "jb.dump(mdl_rf, \"random_forest_20200208.pkl.z\")\n",
    "#jb.dump(lr_pipeline, \"logistic_reg_20200208.pkl.z\")\n",
    "jb.dump(title_vec, \"title_vectorizer_20200208.pkl.z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGORA QUE JA TEMOS MODELOS SALVOS, AGORA É PEGAR EXEMPLOS NOVOS E USAR EM PRODUÇÃO.\n",
    "\n",
    "NÃO USAMOS DATASET DE TESTE AQUI, USAMOS O DATASET DE VALIDAÇÃO PRA TUNAR MODELOS E AJUSTAR COEFICIENTE DO ENSEMBLE. EM GERAL ISSO NAO E PROBLEMA. PODE SER QUE TENHA UM POUCO DE OVERFITING PQ ESTAMOS REUTILIZANDO PRA OTIMIZAR, MAS NAO SERÁ CASTASTŔOFICO, QUE VAMOS OLHAR O SCORE NA VALIDAÇÃO E FALAR \"NOSSA É MUITO DIFERENTE EM PRODUÇÃO, DADOS NOVOS.\"\n",
    "\n",
    "MARIO GOSTAVA MUITO DE SEPARAR EM TREINO, VALIDAÇÃO E TESTE MAS VIU NA PRATICA QUE NÃO HÁ TESTE QUE NEM O TESTE EM PRODUYÇÃO, ENTÃO E IMPORTANTE COLOCAR EM PRODUÇÃO O MAIS RAPIDO POSSIVEL. MAS PODEMOS FAZE MIL TESTES OFFLINE MAS QUANDO COLOCAMOS EM PRODUÇÃO TEM MUITOS DESAFIOS DIFERENTES, DISTRIBUIÇOES DIFERENTES E COISAS DIFERENTES PARA LIDAR. O QUE TEMOS QUE FAZER É COLOCAR EM PRODUÇÃO E SE O MODELO NAO TIVER FUNCIONANDO COMO ESPERADO, INVESTIGAR PARA ARRUMA-LO\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning e Adicionando Features de Texto do Título"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui aindas estamos em um passo hibrido. Criando modelo mas ainda nao saimos da parte de preparação dos dados, pq apesar de termos alguns dados anotados, 500 dados é muito pouco para modelarmos esse tipo de tarefa, principalmente considerando que só 14% são dados positivos, da classe positivo, entao queremos ter mais dados pra que a gente possa modela.\n",
    "\n",
    "Active learning serve pra quando temos orçamento pequeno, então é muito caro fazer anotações em novos exemplos, ou muito pouco tempo para fazer essas anotações, ao inves de sair anotando aleatoriamente os exemplos, vamos fazer as anotações em um determinado numero de exemplos que tenha possibilidade de nos trazer mais ganhos por custo de anotação.\n",
    "\n",
    "Isso é muito importante em dados médicos, pois precisamos de especialistas para estarem avaliando imagens, casos para podes colocar as anotações, se uma radiografia ou ressonancia, tem a doença ou tumor, nesse caso temos uma capacidade limitada e devemos aproveitar ao maximo o tempo desses profissionais. Então assim, seleciona exemplos que tem maior chance de ajudar o modelo a ter uma perfomance melhor ao invés de fazer aleatoriamente.\n",
    "\n",
    "Esse notebook é parecido com o anterior, a diferença que vamos adicionar o texto do titulo e começar a usar uma Random Forest.\n",
    "\n",
    "Carregamos os exemplos anotados, limpeza de data e views exatamente igual.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import time\n",
    "\n",
    "\n",
    "import bs4 as bs4 \n",
    "import json\n",
    "\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"raw_data_with_labels.csv\", index_col=0)\n",
    "df = df[df['y'].notnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = pd.DataFrame(index=df.index)\n",
    "df_limpo['title'] = df['watch-title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date = df['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n",
    "clean_date[0] = clean_date[0].map(lambda x: \"0\"+x[0] if len(x) == 1 else x)\n",
    "#clean_date[1] = clean_date[1].map(lambda x: x[0].upper()+x[1:])\n",
    "\n",
    "mapa_meses = {\"jan\": \"Jan\",\n",
    "              \"fev\": \"Feb\",\n",
    "              \"mar\": \"Mar\", \n",
    "              \"abr\": \"Apr\", \n",
    "              \"mai\": \"May\", \n",
    "              \"jun\": \"Jun\",\n",
    "              \"jul\": \"Jul\",\n",
    "              \"ago\": \"Aug\", \n",
    "              \"set\": \"Sep\", \n",
    "              \"out\": \"Oct\", \n",
    "              \"nov\": \"Nov\",\n",
    "              \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(mapa_meses)\n",
    "\n",
    "clean_date = clean_date.apply(lambda x: \" \".join(x), axis=1)\n",
    "clean_date.head()\n",
    "df_limpo['date'] = pd.to_datetime(clean_date, format=\"%d %b %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpeza de Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False).str.replace(\".\", \"\").fillna(0).astype(int)\n",
    "df_limpo['views'] = views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=df_limpo.index)\n",
    "y = df['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['tempo_desde_pub'] = (pd.to_datetime(\"2019-12-03\") - df_limpo['date']) / np.timedelta64(1, 'D')\n",
    "features['views'] = df_limpo['views']\n",
    "features['views_por_dia'] = features['views'] / features['tempo_desde_pub']\n",
    "features = features.drop(['tempo_desde_pub'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>views_por_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>28028</td>\n",
       "      <td>61.464912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1131</td>\n",
       "      <td>2.960733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1816</td>\n",
       "      <td>8.446512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1171</td>\n",
       "      <td>10.455357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1228</td>\n",
       "      <td>3.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   views  views_por_dia\n",
       "0  28028      61.464912\n",
       "1   1131       2.960733\n",
       "2   1816       8.446512\n",
       "3   1171      10.455357\n",
       "4   1228       3.336957"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, ao invés de fazer igual no outro notebook, que colocamos a seleção de dados na mesma linha que criamos Xtrain, e Xval, criamos mascaras, séries de valores verdadeiros e falsos que selecionam as linhas de acordo com as condições que passei na criar a variavel. Fizemos assim pra economizar espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228, 2), (270, 2), (228,), (270,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_train = df_limpo['date'] < \"2019-04-01\"\n",
    "mask_val = df_limpo['date'] >= \"2019-04-01\"\n",
    "\n",
    "Xtrain, Xval = features[mask_train], features[mask_val]\n",
    "ytrain, yval = y[mask_train], y[mask_val]\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AQUI COMEÇA A NOVIDADE\n",
    "\n",
    "Que é: como a gente vai fazer pra extrair os textos desses videos, ML nao vai entender se simplesmente passar string com os titulos pra ele, então precisamos transformar a string em numeros, algum tipo de numero.\n",
    "\n",
    "Uma das maneiras mais simples de fazer isso e criar uma matriz com a contagem de palavras.\n",
    "\n",
    "Então poderia simplesmente, colocar em cada linha um video e crio uma matriz que cada coluna acaba sendo uma palavra e simplesmente coloco quantas vezes a palavra aparece no cruzamento da linha de determinado video com a palavra que aparece no titulo dele.\n",
    "\n",
    "Existem maneiras mais avançadas de fazer isso. Mario gosta do TF-IDF Vectorizer, é uma formula que vai dar mais peso para palavras que aparecem bastante em um determinado exemplo, mas não tanto no dataset todo que a gente tem. Então palavras  que aparecerem pouco entre todos os videos, mas aparecerem muito em determinado video vao ter valor maior do que palavras muito comuns. Por exemplo, a palavra 'Machine' e 'Learning', devem aparecer muito, então essas palavras vão ter peso menor.\n",
    "\n",
    "E é simples de usar esse transformador de texto no sckiti learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# selecionamos a coluna titulo, dos exemplos de treino e de validação e vamos passar isso para um vetorizador que vai transformar esse texto em uma matriz\n",
    "title_train = df_limpo[mask_train]['title']\n",
    "title_val = df_limpo[mask_val]['title']\n",
    "\n",
    "\n",
    "# chamo de 'bow' pq siginifca 'bag of words', bolsa de palavras, nome que se dá em geral a esse tipo de formato que transformamos as palavras em matriz de documento e termos\n",
    "# para usarmos TfidfVectorizer , criamos uma instância dele que nem nos modelos, só que ao invés de fit e predict, a gente usar o trasnform, pq é uma transformação\n",
    "# o que ele vai ta armazenando aqui, através do fit ? Quais palavras que ele viu, ou seja, palavras que não viu, nao terá colunas indicando se estão ou não no documento\n",
    "# ele vai guardar qual a frequencia delas no nosso dataset, pra depois fazer a multiplicação na fórmula do TD-IDF\n",
    "# e passamos as séries dos titulos, tanto do treino e da validação.\n",
    "# na validação usamos apenas 'transform' se não vou estar ensinao palavras pro meu vetorizador, que eu nao saberia na vida real pq eu nao teria esses exemplos ainda, na vida real nao sei titulo dos videos que vão entra amanha\n",
    "# mas o que é 'min_df=2', ele é um numero minimo que uma palavra precisa aparecer nos dados pra que ela se torne uma coluna\n",
    "\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=2)\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando coloquei 'title_vec = TfidfVectorizer(min_df=1)', ele achou um shape para title_bow_train de (228,742)\n",
    "\n",
    "Ou seja, ele achou 742 palavras nos dados que aparecem pelo menos umas vez, ja que criou 742 colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 193)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colocando min_df = 2, ele achou 193 palavras que aparecem no minimo 2 vezes\n",
    "# quer dizer tbm que a maior parte das palavras só aparece em um vídeo\n",
    "# isso pode atrapalhar o modelo, pois a gente tem um monte coluna que por acidente o modelo pode achar que é preditivo mas não é.\n",
    "# entao mario diz que esse é o primeiro parametro que gosta de tunar quando esta trabalhando com texto\n",
    "# a gente vai ver outro parâmetro tbm num proximo modelo, mas como naõ estamos na parte da modelagem, entao colocamos min_df=2 so pra dar uma reduzida no numero das colunas\n",
    "# na hora da tunagem achamos o parametro ideal\n",
    "title_bow_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERGUNTAR PARA O MARIO ? DA ONDE VIRIAM ESSES DADOS ZERO ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padrão, TF-IDF ele te da uma matriz sparsa, que é uma matriz otimizada dentro do scipy, que é o pacote irmão do numpy.\n",
    "\n",
    "O QUE É UMA MATRIZ SPARSA ? Ele só vai armazenar valores que forem diferentes de zero. Ele ta dizendo que tem 1277 elementos, se a gente fosse armazenar todos os elementos na memoria, inclusive os zeros, teriamos (228*193)=44004 elementos, então a gente ta usando muito menos memoria sem perder poder de representação.\n",
    "\n",
    "1 - 1277/(228*193) = 0.9709799\n",
    "\n",
    "Temos que cerca de 97% da nossa matriz é composta de zeros, ou seja, ela é sparsa tanto do ponto de vista matematico quanto computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resposta do MARIO FILHO A MINHA PERGUNTA \n",
    "\n",
    "PERGUNTA: A partir de 08:20, não consegui entender. Matriz Esparsa ele armazena valores diferentes de zero, mas depois diz que 97% da matriz é composta de zeros. Ficou meio abstrato, não conseguir visualizar. Tipo, como é feita a composição da matriz se ela armazena valores diferentes de zero, e pensarmos que uma linha representada por um vídeo, terá vários valores zero pois a maioria das colunas, que são as palavras, não estarão contidas no seu título.\n",
    "\n",
    "\n",
    "RESPOSTA: Jarbas, 97% da matriz, matematicamente, é de zeros. Mas como não vale a pena armazenar os zeros, Ela armazena (na memória) apenas valores diferentes de zero. Quando ela for consultar um elemento e ele não estiver armazenado, retorna zero. Intuitivamente pode pensar numa matriz que tem a linha cheia de zeros, sendo números diferentes de zero apenas nos elementos correspondentes a colunas de palavras que estão no título do vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "to_array not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-81e9f1a356b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitle_bow_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: to_array not found"
     ]
    }
   ],
   "source": [
    "title_bow_train.to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como que a gente faz quando temos dados que são númericos, variaveis numericas mas tambem de texto.\n",
    "\n",
    "Não tem problema nenhum juntar essas variaveis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Xtrain temos as duas variaveis que ja tinhamos, e agora temos o title_bow_train e val com a representação de texto.\n",
    "\n",
    "O que eu preciso fazer(IMPORTANTE) é usar a função 'hstack' do scipy sparse.\n",
    "\n",
    "O QUE ELAS FAZEM ? O numpy tbm tem essas funções. Elas pegam matrizes, no caso do exemplo: vetores, e hstack junta elas horizontalmente.\n",
    "\n",
    "hstack - [1 2]     [3 4]   ---> [1 2 3 4] - 1x4\n",
    "\n",
    "Se eu passar pra vstack, ele coloca um embaixo do outro.\n",
    "\n",
    "vstack - [1 2]     [3 4]   ---> [1 2]\n",
    "                                [3 4] - 2x2\n",
    "                                \n",
    "Basicamente, a concatenação horizontal e vertical que estamos lidando aqui.\n",
    "\n",
    "Importante que seja scipy sparse, pq usando do numpy demora muito, pq nao e otimizado para utilizar matriz sparsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "Xtrain_wtitle = hstack([Xtrain, title_bow_train])\n",
    "Xval_wtitle = hstack([Xval, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shape após juntar X_train com title_bow_train e Xval com title_bow_val.\n",
    "# 193 da representação textual mais 2 das features númericas.\n",
    "# modo padrão de lidar com essa situação.\n",
    "\n",
    "Xtrain_wtitle.shape, Xval_wtitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora treinando o modelo. Mario sempre usa random forest.\n",
    "\n",
    "Modelo simples, colocamos 1000 árvores, 'balanced' pra equilibrar as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced', n_jobs=6)\n",
    "mdl.fit(Xtrain_wtitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(Xval_wtitle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(yval, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(yval, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns experimentos que Mario fez mudando min_df pra 1 e 2\n",
    "\n",
    "ap 0.17683995211083103, auc 0.6036474164133738 - mindf=1\n",
    "ap 0.1918043901336543, auc 0.5848024316109421 - mindf=2\n",
    "\n",
    "\n",
    "Quando eu aumento o min_df, de 1 pra 2, average de precision aumenta mas auc cai, e o que eu to procurando são parametros e features que quando eu adiciono ao modelo ele melhore as duas métricas, nesse caso uma ta melhorando e outra ta piorando.\n",
    "\n",
    "auc ta variando mutio pq tenho poucos exemplos positivos, entao nao to confiando tanto no auc pq temos pouca quantidade dados, e com min_df=2 a chance de overfitign é menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELEMBRAR COMO FUNCIONA A CURVA ROC : https://www.youtube.com/watch?v=Y1XAP6omGzo\n",
    "\n",
    "RELEMBRAR AVERAGE PRECISION SCORE: https://www.youtube.com/watch?v=QdWidmgLwbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dizer que eu só tenho orçamento para fazer anotações em mais 100 exemplos, então eu seleciono:\n",
    "\n",
    "70 exemplos que o modelo tenha dificuldade\n",
    "30 aleatoriedade\n",
    "\n",
    "Pq eu não seleciono 100 exemplos que o modelo tenha dificuldade ? Não é pq o modelo ta com dificuldades em alguns exemplos que esses serão as unicas dificuldades que o modelo terá, pode ser que ele ainda nem encontrou algum outro tipo de erro ou exemplo que tenha um padrão diferente de tudo que a gente tem ate agora nos nossos dados de treino, por isso é bom deixar uma parte dos dados ainda sendo selecionadas aleatoriamente para o active learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df nao anotado, selecionei todas as linhas que nao tem y preenchido, coloquei dropna tira todoas as linhas que tem todos os campos 'nan'\n",
    "\n",
    "df_unlabeled = pd.read_csv(\"raw_data_with_labels.csv\", index_col=0)\n",
    "df_unlabeled = df_unlabeled[df_unlabeled['y'].isnull()].dropna(how='all')\n",
    "df_unlabeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo_u = pd.DataFrame(index=df_unlabeled.index)\n",
    "df_limpo_u['title'] = df_unlabeled['watch-title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AQUI USAMOS AS MESMAS FUNÇÕES DOS ULTIMOS DOIS CÓDIGOS, LIMPEZA DE DADOS, VIEWS E FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date = df_unlabeled['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n",
    "clean_date[0] = clean_date[0].map(lambda x: \"0\"+x[0] if len(x) == 1 else x)\n",
    "#clean_date[1] = clean_date[1].map(lambda x: x[0].upper()+x[1:])\n",
    "\n",
    "mapa_meses = {\"jan\": \"Jan\",\n",
    "              \"fev\": \"Feb\",\n",
    "              \"mar\": \"Mar\", \n",
    "              \"abr\": \"Apr\", \n",
    "              \"mai\": \"May\", \n",
    "              \"jun\": \"Jun\",\n",
    "              \"jul\": \"Jul\",\n",
    "              \"ago\": \"Aug\", \n",
    "              \"set\": \"Sep\", \n",
    "              \"out\": \"Oct\", \n",
    "              \"nov\": \"Nov\",\n",
    "              \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(mapa_meses)\n",
    "\n",
    "clean_date = clean_date.apply(lambda x: \" \".join(x), axis=1)\n",
    "clean_date.head()\n",
    "df_limpo_u['date'] = pd.to_datetime(clean_date, format=\"%d %b %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = df_unlabeled['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False).str.replace(\".\", \"\").fillna(0).astype(int)\n",
    "df_limpo_u['views'] = views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_u = pd.DataFrame(index=df_limpo_u.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_u['tempo_desde_pub'] = (pd.to_datetime(\"2019-12-03\") - df_limpo_u['date']) / np.timedelta64(1, 'D')\n",
    "features_u['views'] = df_limpo_u['views']\n",
    "features_u['views_por_dia'] = features_u['views'] / features_u['tempo_desde_pub']\n",
    "features_u = features_u.drop(['tempo_desde_pub'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_u.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa vez eu não vou criar um novo TF-IDF vectorizer, ja tenho um modelo de random forest treinada anteriormente, entao vamos usa-la pra prever e entao conseguir selecionar os exemplos que o modelo está com dificuldade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "title_u = df_limpo_u['title']\n",
    "title_bow_u = title_vec.transform(title_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_bow_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo o hstack\n",
    "Xu_wtitle = hstack([features_u, title_bow_u])\n",
    "Xu_wtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agora é a previsão para esses dados que nao estão anotados\n",
    "pu = mdl.predict_proba(Xu_wtitle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coloquei uma coluna nova 'p' com as novas previsões\n",
    "df_unlabeled['p'] = pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embora 'p' pareça uma probabilidade, não é exatamente, pois estamos dando pesos diferentes pra classe positiva, mas não rigorosamente a gente pode entender como probabilidade, mas como uma pontuação\n",
    "df_unlabeled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como que eu sei que um exemplo é dificil para o modelo ?\n",
    "\n",
    "Novamente, vamos ver quais estão proximos de 50% de probabilidade, entre 0.45 e 0.55, ele está mais confuso.\n",
    "\n",
    "Como se ele tivesse jogando uma moeda para definir qual é a classe. DESSA MANEIRA DESCOBRIMOS A DIFICULDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_u = (df_unlabeled['p'] >= 0.45) & (df_unlabeled['p'] <= 0.55)\n",
    "mask_u.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui vemos que tem só 12 exemplos, vamos dar uma olhada\n",
    "# se a gente der anotações para esses exemplos, pode ser que ele consiga puxar a fronteira dele de classificação, e assim ter mais certeza para classificar corretamente\n",
    "df_unlabeled[mask_u]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como eu quero 70 exemplos, mario expeculou com os valores da mask, até ter o numero que queria de exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_u = (df_unlabeled['p'] >= 0.26) & (df_unlabeled['p'] <= 1.)\n",
    "mask_u.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# todas da serie que possuem 'True' estão com as probabilidades entre as definidas acima\n",
    "mask_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dificeis = df_unlabeled[mask_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como combinado era 70 entre as mais dificeis e outras 30, aleatorias, definimos isso aproximado aqui\n",
    "# '~', simplesmente e como se fosse um negado, que traz amostras de tudo que não contém em mask_u\n",
    "# se quiser definir que sempre sejam os mesmos valores, definir random state\n",
    "aleatorios = df_unlabeled[~mask_u].sample(31, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dificeis, aleatorios]).to_csv(\"active_label1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COM ESSE CSV, VOU CARREGAR NO GOOGLE SHEET E DEFINIR OS QUE EU GOSTO E NÃO GOSTO PARA ALIMENTAR O MODELO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
